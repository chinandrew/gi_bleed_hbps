{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "from bayesbridge import BayesBridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify mean and sd in log10 scale and find the matching prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge_exponent = 1 / 8\n",
    "log10_mean = - 4.\n",
    "log10_sd = 1.\n",
    "gscale_parametrization = ['raw', 'coefficient'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy data just to initialize BayesBridge\n",
    "y = np.random.randn(10)\n",
    "X = np.random.randn(10, 2)\n",
    "bridge = BayesBridge(y, X, global_scale_parametrization=gscale_parametrization)\n",
    "bridge.set_global_scale_prior(log10_mean, log10_sd, bridge_exponent)\n",
    "prior_param = bridge.prior_param['gscale_neg_power']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that the prior indeed has the specified mean and sd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = prior_param['shape']\n",
    "scale = prior_param['rate'] ** -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 10 ** 6\n",
    "samples = np.random.gamma(shape, scale, size=n_sample) ** (- 1 / bridge_exponent)\n",
    "if gscale_parametrization == 'coefficient':\n",
    "    samples *= bridge.compute_power_exp_ave_magnitude(bridge_exponent, 1.)\n",
    "log10_gscale_samples = np.log10(samples)\n",
    "\n",
    "mean_est = np.mean(log10_gscale_samples)\n",
    "sd_est = np.std(log10_gscale_samples)\n",
    "\n",
    "rtol = .01\n",
    "mean_is_close = abs((mean_est - log10_mean) / log10_mean) < rtol\n",
    "sd_is_close = abs((sd_est - log10_sd) / log10_sd) < rtol\n",
    "if mean_is_close and sd_is_close:\n",
    "    print(\"Monte Carlo estimates agree with theoretical values.\")\n",
    "else:\n",
    "    print(\"Warning! Monte Carlo estimates do NOT agree with theoretical values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.rcParams['font.size'] = 18\n",
    "\n",
    "plt.hist(\n",
    "    log10_gscale_samples, bins=51, density=True,\n",
    "    label='prior dist.'\n",
    ")\n",
    "plt.axvline(\n",
    "    mean_est, linestyle='--', color='tab:orange',\n",
    "    label='mean'\n",
    ")\n",
    "plt.axvline(\n",
    "    mean_est + 2 * sd_est, linestyle='--', color='tab:olive',\n",
    "    label=r'mean $\\pm$ 2 std'\n",
    ")\n",
    "plt.axvline(\n",
    "    mean_est - 2 * sd_est, linestyle='--', color='tab:olive'\n",
    ")\n",
    "plt.xlabel(r'$\\log(\\tau)$')\n",
    "plt.yticks([])\n",
    "plt.legend(frameon=False)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
